[
  {
    "name": "nomic-ai/nomic-embed-text-v1.5",
    "provider": "Nomic",
    "parameter_count": "137M",
    "parameters_raw": 137000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "F16",
    "context_length": 8192,
    "use_case": "Text embeddings for RAG",
    "pipeline_tag": "feature-extraction",
    "architecture": "nomic_bert",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "BAAI/bge-large-en-v1.5",
    "provider": "BAAI",
    "parameter_count": "335M",
    "parameters_raw": 335142400,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "Q4_K_M",
    "context_length": 512,
    "use_case": "Text embeddings for RAG",
    "pipeline_tag": "feature-extraction",
    "architecture": "bert",
    "hf_downloads": 4887046,
    "hf_likes": 627
  },
  {
    "name": "Qwen/Qwen3-0.6B",
    "provider": "Alibaba",
    "parameter_count": "600M",
    "parameters_raw": 600000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-3-1b-it",
    "provider": "Google",
    "parameter_count": "1B",
    "parameters_raw": 1000000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "gemma3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "provider": "Community",
    "parameter_count": "1.1B",
    "parameters_raw": 1100048384,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.6,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1770914,
    "hf_likes": 1526
  },
  {
    "name": "meta-llama/Llama-3.2-1B",
    "provider": "Meta",
    "parameter_count": "1.2B",
    "parameters_raw": 1235814400,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1853952,
    "hf_likes": 2293
  },
  {
    "name": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "1.5B",
    "parameters_raw": 1543714304,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1501360,
    "hf_likes": 106
  },
  {
    "name": "stabilityai/stablelm-2-1_6b-chat",
    "provider": "Stability AI",
    "parameter_count": "1.6B",
    "parameters_raw": 1644515328,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.8,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "stablelm",
    "hf_downloads": 403,
    "hf_likes": 34
  },
  {
    "name": "Qwen/Qwen3-1.7B",
    "provider": "Alibaba",
    "parameter_count": "1.7B",
    "parameters_raw": 1720000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.9,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-2-2b-it",
    "provider": "Google",
    "parameter_count": "2.6B",
    "parameters_raw": 2614341888,
    "min_ram_gb": 1.5,
    "recommended_ram_gb": 2.4,
    "min_vram_gb": 1.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 334622,
    "hf_likes": 1284
  },
  {
    "name": "ibm-granite/granite-4.0-h-micro",
    "provider": "IBM",
    "parameter_count": "3B",
    "parameters_raw": 3000000000,
    "min_ram_gb": 1.7,
    "recommended_ram_gb": 2.8,
    "min_vram_gb": 1.5,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Enterprise, hybrid Mamba/transformer",
    "pipeline_tag": "text-generation",
    "architecture": "granite_hybrid",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/Llama-3.2-3B",
    "provider": "Meta",
    "parameter_count": "3.2B",
    "parameters_raw": 3212749824,
    "min_ram_gb": 1.8,
    "recommended_ram_gb": 3.0,
    "min_vram_gb": 1.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 803855,
    "hf_likes": 697
  },
  {
    "name": "microsoft/phi-3-mini-4k-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-3.5-mini-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Lightweight, long context",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-VL-3B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "image-text-to-text",
    "architecture": "qwen2_vl",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-4-mini-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3840000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "phi4",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-3-4b-it",
    "provider": "Google",
    "parameter_count": "4B",
    "parameters_raw": 4000000000,
    "min_ram_gb": 2.2,
    "recommended_ram_gb": 3.7,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Lightweight, general purpose",
    "pipeline_tag": "text-generation",
    "architecture": "gemma3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-4B",
    "provider": "Alibaba",
    "parameter_count": "4.0B",
    "parameters_raw": 4020000000,
    "min_ram_gb": 2.2,
    "recommended_ram_gb": 3.7,
    "min_vram_gb": 2.1,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "01-ai/Yi-6B-Chat",
    "provider": "01.ai",
    "parameter_count": "6.1B",
    "parameters_raw": 6061035520,
    "min_ram_gb": 3.4,
    "recommended_ram_gb": 5.6,
    "min_vram_gb": 3.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 12988,
    "hf_likes": 70
  },
  {
    "name": "lmsys/vicuna-7b-v1.5",
    "provider": "LMSYS",
    "parameter_count": "7.0B",
    "parameters_raw": 6738415616,
    "min_ram_gb": 3.8,
    "recommended_ram_gb": 6.3,
    "min_vram_gb": 3.4,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/CodeLlama-7b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "6.7B",
    "parameters_raw": 6738546688,
    "min_ram_gb": 3.8,
    "recommended_ram_gb": 6.3,
    "min_vram_gb": 3.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 3305,
    "hf_likes": 59
  },
  {
    "name": "openchat/openchat-3.5-0106",
    "provider": "OpenChat",
    "parameter_count": "7.0B",
    "parameters_raw": 7000000000,
    "min_ram_gb": 3.9,
    "recommended_ram_gb": 6.5,
    "min_vram_gb": 3.6,
    "quantization": "Q4_K_M",
    "context_length": 8192,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "ibm-granite/granite-4.0-h-tiny",
    "provider": "IBM",
    "parameter_count": "7B",
    "parameters_raw": 7000000000,
    "min_ram_gb": 3.9,
    "recommended_ram_gb": 6.5,
    "min_vram_gb": 3.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Enterprise, hybrid Mamba/transformer",
    "pipeline_tag": "text-generation",
    "architecture": "granite_hybrid",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 32,
    "active_experts": 4,
    "active_parameters": 1000000000
  },
  {
    "name": "microsoft/Orca-2-7b",
    "provider": "Microsoft",
    "parameter_count": "7.0B",
    "parameters_raw": 7016400896,
    "min_ram_gb": 3.9,
    "recommended_ram_gb": 6.5,
    "min_vram_gb": 3.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Reasoning, step-by-step solutions",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "bigcode/starcoder2-7b",
    "provider": "BigCode",
    "parameter_count": "7.2B",
    "parameters_raw": 7173923840,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder2",
    "hf_downloads": 16730,
    "hf_likes": 209
  },
  {
    "name": "tiiuae/falcon-7b-instruct",
    "provider": "TII",
    "parameter_count": "7.2B",
    "parameters_raw": 7217189760,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 42085,
    "hf_likes": 1030
  },
  {
    "name": "HuggingFaceH4/zephyr-7b-beta",
    "provider": "HuggingFace",
    "parameter_count": "7.2B",
    "parameters_raw": 7241732096,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 74535,
    "hf_likes": 1833
  },
  {
    "name": "mistralai/Mistral-7B-Instruct-v0.3",
    "provider": "Mistral AI",
    "parameter_count": "7.2B",
    "parameters_raw": 7248023552,
    "min_ram_gb": 4.1,
    "recommended_ram_gb": 6.8,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mistral",
    "hf_downloads": 1200708,
    "hf_likes": 2419
  },
  {
    "name": "tiiuae/Falcon3-7B-Instruct",
    "provider": "TII",
    "parameter_count": "7.5B",
    "parameters_raw": 7500000000,
    "min_ram_gb": 4.2,
    "recommended_ram_gb": 7.0,
    "min_vram_gb": 3.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 12751133,
    "hf_likes": 1072
  },
  {
    "name": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1372433,
    "hf_likes": 643
  },
  {
    "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "provider": "DeepSeek",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 707158,
    "hf_likes": 787
  },
  {
    "name": "meta-llama/Llama-3.1-8B",
    "provider": "Meta",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1205931,
    "hf_likes": 2062
  },
  {
    "name": "meta-llama/Llama-3.1-8B-Instruct",
    "provider": "Meta",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 5713509,
    "hf_likes": 5457
  },
  {
    "name": "mistralai/Ministral-8B-Instruct-2410",
    "provider": "Mistral AI",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "ibm-granite/granite-3.1-8b-instruct",
    "provider": "IBM",
    "parameter_count": "8.1B",
    "parameters_raw": 8100000000,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Enterprise, instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "granite",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-8B",
    "provider": "Alibaba",
    "parameter_count": "8.2B",
    "parameters_raw": 8190735360,
    "min_ram_gb": 4.6,
    "recommended_ram_gb": 7.6,
    "min_vram_gb": 4.2,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 4685993,
    "hf_likes": 934
  },
  {
    "name": "Qwen/Qwen2.5-VL-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "8.3B",
    "parameters_raw": 8290000000,
    "min_ram_gb": 4.6,
    "recommended_ram_gb": 7.7,
    "min_vram_gb": 4.2,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "image-text-to-text",
    "architecture": "qwen2_vl",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "THUDM/glm-4-9b-chat",
    "provider": "Zhipu AI",
    "parameter_count": "9B",
    "parameters_raw": 9000000000,
    "min_ram_gb": 5.0,
    "recommended_ram_gb": 8.4,
    "min_vram_gb": 4.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multilingual, instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "glm4",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-2-9b-it",
    "provider": "Google",
    "parameter_count": "9.2B",
    "parameters_raw": 9241705984,
    "min_ram_gb": 5.2,
    "recommended_ram_gb": 8.6,
    "min_vram_gb": 4.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 136774,
    "hf_likes": 768
  },
  {
    "name": "tiiuae/Falcon3-10B-Instruct",
    "provider": "TII",
    "parameter_count": "10.3B",
    "parameters_raw": 10300000000,
    "min_ram_gb": 5.8,
    "recommended_ram_gb": 9.6,
    "min_vram_gb": 5.3,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "provider": "Meta",
    "parameter_count": "10.7B",
    "parameters_raw": 10670220835,
    "min_ram_gb": 6.0,
    "recommended_ram_gb": 9.9,
    "min_vram_gb": 5.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "image-text-to-text",
    "architecture": "mllama",
    "hf_downloads": 170781,
    "hf_likes": 1563
  },
  {
    "name": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "provider": "Upstage",
    "parameter_count": "10.7B",
    "parameters_raw": 10700000000,
    "min_ram_gb": 6.0,
    "recommended_ram_gb": 10.0,
    "min_vram_gb": 5.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "High-performance instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-3-12b-it",
    "provider": "Google",
    "parameter_count": "12B",
    "parameters_raw": 12000000000,
    "min_ram_gb": 6.7,
    "recommended_ram_gb": 11.2,
    "min_vram_gb": 6.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "text-generation",
    "architecture": "gemma3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mistral-Nemo-Instruct-2407",
    "provider": "Mistral AI",
    "parameter_count": "12.2B",
    "parameters_raw": 12247076864,
    "min_ram_gb": 6.8,
    "recommended_ram_gb": 11.4,
    "min_vram_gb": 6.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Orca-2-13b",
    "provider": "Microsoft",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Reasoning, step-by-step solutions",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "lmsys/vicuna-13b-v1.5",
    "provider": "LMSYS",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "WizardLMTeam/WizardLM-13B-V1.2",
    "provider": "WizardLM",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/CodeLlama-13b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "13.0B",
    "parameters_raw": 13016028160,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 3852,
    "hf_likes": 27
  },
  {
    "name": "microsoft/phi-4",
    "provider": "Microsoft",
    "parameter_count": "14B",
    "parameters_raw": 14000000000,
    "min_ram_gb": 7.8,
    "recommended_ram_gb": 13.0,
    "min_vram_gb": 7.2,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Reasoning, STEM, code generation",
    "pipeline_tag": "text-generation",
    "architecture": "phi",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-3-medium-14b-instruct",
    "provider": "Microsoft",
    "parameter_count": "14B",
    "parameters_raw": 14000000000,
    "min_ram_gb": 7.8,
    "recommended_ram_gb": 13.0,
    "min_vram_gb": 7.2,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Balanced performance and size",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-14B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770000000,
    "min_ram_gb": 8.2,
    "recommended_ram_gb": 13.7,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-14B",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770000000,
    "min_ram_gb": 8.2,
    "recommended_ram_gb": 13.7,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-Coder-14B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770033664,
    "min_ram_gb": 8.3,
    "recommended_ram_gb": 13.8,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 382626,
    "hf_likes": 140
  },
  {
    "name": "WizardLMTeam/WizardCoder-15B-V1.0",
    "provider": "WizardLM",
    "parameter_count": "15.5B",
    "parameters_raw": 15515334656,
    "min_ram_gb": 8.7,
    "recommended_ram_gb": 14.5,
    "min_vram_gb": 7.9,
    "quantization": "Q4_K_M",
    "context_length": 8192,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "bigcode/starcoder2-15b",
    "provider": "BigCode",
    "parameter_count": "15.7B",
    "parameters_raw": 15700000000,
    "min_ram_gb": 8.8,
    "recommended_ram_gb": 14.6,
    "min_vram_gb": 8.0,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "provider": "DeepSeek",
    "parameter_count": "16B",
    "parameters_raw": 15700000000,
    "min_ram_gb": 8.8,
    "recommended_ram_gb": 14.6,
    "min_vram_gb": 8.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v2",
    "is_moe": true,
    "num_experts": 64,
    "active_experts": 6,
    "active_parameters": 2400000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "inclusionAI/Ling-lite",
    "provider": "Ant Group",
    "parameter_count": "16.8B",
    "parameters_raw": 16800000000,
    "min_ram_gb": 9.4,
    "recommended_ram_gb": 15.6,
    "min_vram_gb": 8.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Efficient MoE, general purpose",
    "pipeline_tag": "text-generation",
    "architecture": "ling",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 32,
    "active_experts": 2,
    "active_parameters": 2750000000
  },
  {
    "name": "mistralai/Mistral-Small-24B-Instruct-2501",
    "provider": "Mistral AI",
    "parameter_count": "24B",
    "parameters_raw": 24000000000,
    "min_ram_gb": 13.4,
    "recommended_ram_gb": 22.4,
    "min_vram_gb": 12.3,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "provider": "Mistral AI",
    "parameter_count": "24B",
    "parameters_raw": 24000000000,
    "min_ram_gb": 13.4,
    "recommended_ram_gb": 22.4,
    "min_vram_gb": 12.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-3-27b-it",
    "provider": "Google",
    "parameter_count": "27B",
    "parameters_raw": 27000000000,
    "min_ram_gb": 15.1,
    "recommended_ram_gb": 25.1,
    "min_vram_gb": 13.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-2-27b-it",
    "provider": "Google",
    "parameter_count": "27.2B",
    "parameters_raw": 27227128320,
    "min_ram_gb": 15.2,
    "recommended_ram_gb": 25.4,
    "min_vram_gb": 13.9,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 387056,
    "hf_likes": 559
  },
  {
    "name": "Qwen/Qwen3-30B-A3B",
    "provider": "Alibaba",
    "parameter_count": "30.5B",
    "parameters_raw": 30530000000,
    "min_ram_gb": 17.1,
    "recommended_ram_gb": 28.4,
    "min_vram_gb": 15.6,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "Efficient MoE, general purpose",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 3300000000
  },
  {
    "name": "ibm-granite/granite-4.0-h-small",
    "provider": "IBM",
    "parameter_count": "32B",
    "parameters_raw": 32000000000,
    "min_ram_gb": 17.9,
    "recommended_ram_gb": 29.8,
    "min_vram_gb": 16.4,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Enterprise, hybrid Mamba/transformer",
    "pipeline_tag": "text-generation",
    "architecture": "granite_hybrid",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 32,
    "active_experts": 4,
    "active_parameters": 9000000000
  },
  {
    "name": "allenai/OLMo-2-0325-32B-Instruct",
    "provider": "Allen Institute",
    "parameter_count": "32B",
    "parameters_raw": 32000000000,
    "min_ram_gb": 17.9,
    "recommended_ram_gb": 29.8,
    "min_vram_gb": 16.4,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Fully open-source, instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "olmo2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-32B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "32.5B",
    "parameters_raw": 32510000000,
    "min_ram_gb": 18.2,
    "recommended_ram_gb": 30.3,
    "min_vram_gb": 16.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-32B",
    "provider": "Alibaba",
    "parameter_count": "32.8B",
    "parameters_raw": 32762123264,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 1560791,
    "hf_likes": 654
  },
  {
    "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "32.8B",
    "parameters_raw": 32763876352,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 734607,
    "hf_likes": 1994
  },
  {
    "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "provider": "DeepSeek",
    "parameter_count": "32.8B",
    "parameters_raw": 32763876352,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1226387,
    "hf_likes": 1515
  },
  {
    "name": "meta-llama/CodeLlama-34b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "33.7B",
    "parameters_raw": 33743970304,
    "min_ram_gb": 18.9,
    "recommended_ram_gb": 31.4,
    "min_vram_gb": 17.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1067,
    "hf_likes": 18
  },
  {
    "name": "01-ai/Yi-34B-Chat",
    "provider": "01.ai",
    "parameter_count": "34.4B",
    "parameters_raw": 34388917248,
    "min_ram_gb": 19.2,
    "recommended_ram_gb": 32.0,
    "min_vram_gb": 17.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 13208,
    "hf_likes": 357
  },
  {
    "name": "CohereForAI/c4ai-command-r-v01",
    "provider": "Cohere",
    "parameter_count": "35B",
    "parameters_raw": 35000000000,
    "min_ram_gb": 19.5,
    "recommended_ram_gb": 32.6,
    "min_vram_gb": 17.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "RAG, tool use, agents",
    "pipeline_tag": "text-generation",
    "architecture": "cohere",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "tiiuae/falcon-40b-instruct",
    "provider": "TII",
    "parameter_count": "40.0B",
    "parameters_raw": 40000000000,
    "min_ram_gb": 22.4,
    "recommended_ram_gb": 37.3,
    "min_vram_gb": 20.5,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "provider": "Mistral AI",
    "parameter_count": "46.7B",
    "parameters_raw": 46702792704,
    "min_ram_gb": 26.1,
    "recommended_ram_gb": 43.5,
    "min_vram_gb": 23.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mixtral",
    "hf_downloads": 542837,
    "hf_likes": 4639,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 12900000000
  },
  {
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "provider": "NousResearch",
    "parameter_count": "46.7B",
    "parameters_raw": 46702809088,
    "min_ram_gb": 26.1,
    "recommended_ram_gb": 43.5,
    "min_vram_gb": 23.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "mixtral",
    "hf_downloads": 8064,
    "hf_likes": 453,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 12900000000
  },
  {
    "name": "meta-llama/Llama-3.1-70B-Instruct",
    "provider": "Meta",
    "parameter_count": "70.6B",
    "parameters_raw": 70553706496,
    "min_ram_gb": 39.4,
    "recommended_ram_gb": 65.7,
    "min_vram_gb": 36.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 707708,
    "hf_likes": 888
  },
  {
    "name": "meta-llama/Llama-3.3-70B-Instruct",
    "provider": "Meta",
    "parameter_count": "70.6B",
    "parameters_raw": 70553706496,
    "min_ram_gb": 39.4,
    "recommended_ram_gb": 65.7,
    "min_vram_gb": 36.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-72B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "72.7B",
    "parameters_raw": 72706203648,
    "min_ram_gb": 40.6,
    "recommended_ram_gb": 67.7,
    "min_vram_gb": 37.2,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 336890,
    "hf_likes": 910
  },
  {
    "name": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "provider": "Meta",
    "parameter_count": "109B",
    "parameters_raw": 109000000000,
    "min_ram_gb": 60.9,
    "recommended_ram_gb": 101.5,
    "min_vram_gb": 55.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "image-text-to-text",
    "architecture": "llama4",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 16,
    "active_experts": 1,
    "active_parameters": 17000000000
  },
  {
    "name": "mistralai/Mistral-Large-Instruct-2407",
    "provider": "Mistral AI",
    "parameter_count": "123B",
    "parameters_raw": 123000000000,
    "min_ram_gb": 68.7,
    "recommended_ram_gb": 114.6,
    "min_vram_gb": 63.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Large-scale instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "provider": "Mistral AI",
    "parameter_count": "140.6B",
    "parameters_raw": 140600000000,
    "min_ram_gb": 78.6,
    "recommended_ram_gb": 130.9,
    "min_vram_gb": 72.0,
    "quantization": "Q4_K_M",
    "context_length": 65536,
    "use_case": "Large MoE, instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "mixtral",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 39100000000
  },
  {
    "name": "rednote-hilab/dots.llm1.inst",
    "provider": "Rednote",
    "parameter_count": "142B",
    "parameters_raw": 142000000000,
    "min_ram_gb": 79.3,
    "recommended_ram_gb": 132.2,
    "min_vram_gb": 72.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "MoE, general purpose",
    "pipeline_tag": "text-generation",
    "architecture": "dots",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 64,
    "active_experts": 8,
    "active_parameters": 14000000000
  },
  {
    "name": "bigscience/bloom",
    "provider": "BigScience",
    "parameter_count": "176B",
    "parameters_raw": 176000000000,
    "min_ram_gb": 98.3,
    "recommended_ram_gb": 163.9,
    "min_vram_gb": 90.2,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Multilingual text generation",
    "pipeline_tag": "text-generation",
    "architecture": "bloom",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "tiiuae/falcon-180B-chat",
    "provider": "TII",
    "parameter_count": "180B",
    "parameters_raw": 180000000000,
    "min_ram_gb": 100.6,
    "recommended_ram_gb": 167.6,
    "min_vram_gb": 92.2,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Large-scale instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-235B-A22B",
    "provider": "Alibaba",
    "parameter_count": "235B",
    "parameters_raw": 235000000000,
    "min_ram_gb": 131.3,
    "recommended_ram_gb": 218.9,
    "min_vram_gb": 120.4,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "State-of-the-art, MoE architecture",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 22000000000
  },
  {
    "name": "baidu/ERNIE-4.5-300B-A47B-Paddle",
    "provider": "Baidu",
    "parameter_count": "300B",
    "parameters_raw": 300000000000,
    "min_ram_gb": 167.6,
    "recommended_ram_gb": 279.4,
    "min_vram_gb": 153.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multilingual, reasoning",
    "pipeline_tag": "text-generation",
    "architecture": "ernie",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 47000000000
  },
  {
    "name": "xai-org/grok-1",
    "provider": "xAI",
    "parameter_count": "314B",
    "parameters_raw": 314000000000,
    "min_ram_gb": 175.5,
    "recommended_ram_gb": 292.4,
    "min_vram_gb": 160.8,
    "quantization": "Q4_K_M",
    "context_length": 8192,
    "use_case": "Large MoE, general purpose",
    "pipeline_tag": "text-generation",
    "architecture": "grok",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 86000000000
  },
  {
    "name": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
    "provider": "Meta",
    "parameter_count": "400B",
    "parameters_raw": 400000000000,
    "min_ram_gb": 223.5,
    "recommended_ram_gb": 372.5,
    "min_vram_gb": 204.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "image-text-to-text",
    "architecture": "llama4",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 1,
    "active_parameters": 17000000000
  },
  {
    "name": "meta-llama/Llama-3.1-405B-Instruct",
    "provider": "Meta",
    "parameter_count": "405.9B",
    "parameters_raw": 405853388800,
    "min_ram_gb": 226.8,
    "recommended_ram_gb": 378.0,
    "min_vram_gb": 207.9,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 147548,
    "hf_likes": 592
  },
  {
    "name": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "480B",
    "parameters_raw": 480000000000,
    "min_ram_gb": 268.2,
    "recommended_ram_gb": 447.0,
    "min_vram_gb": 245.9,
    "quantization": "Q4_K_M",
    "context_length": 262144,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 35000000000
  },
  {
    "name": "meituan/LongCat-Flash",
    "provider": "Meituan",
    "parameter_count": "560B",
    "parameters_raw": 560000000000,
    "min_ram_gb": 312.9,
    "recommended_ram_gb": 521.5,
    "min_vram_gb": 286.8,
    "quantization": "Q4_K_M",
    "context_length": 524288,
    "use_case": "Long context MoE",
    "pipeline_tag": "text-generation",
    "architecture": "longcat",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 18600000000
  },
  {
    "name": "deepseek-ai/DeepSeek-R1",
    "provider": "DeepSeek",
    "parameter_count": "671B",
    "parameters_raw": 671000000000,
    "min_ram_gb": 375.0,
    "recommended_ram_gb": 624.9,
    "min_vram_gb": 343.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v3",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 256,
    "active_experts": 8,
    "active_parameters": 37000000000
  },
  {
    "name": "deepseek-ai/DeepSeek-V3",
    "provider": "DeepSeek",
    "parameter_count": "685B",
    "parameters_raw": 685000000000,
    "min_ram_gb": 382.8,
    "recommended_ram_gb": 638.0,
    "min_vram_gb": 351.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "State-of-the-art, MoE architecture",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v3",
    "is_moe": true,
    "num_experts": 256,
    "active_experts": 8,
    "active_parameters": 37000000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "moonshotai/Kimi-K2-Instruct",
    "provider": "Moonshot",
    "parameter_count": "1000B",
    "parameters_raw": 1000000000000,
    "min_ram_gb": 558.8,
    "recommended_ram_gb": 931.3,
    "min_vram_gb": 512.2,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Large MoE, reasoning",
    "pipeline_tag": "text-generation",
    "architecture": "kimi",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 384,
    "active_experts": 8,
    "active_parameters": 32000000000
  }
]